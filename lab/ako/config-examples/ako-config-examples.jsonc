// Uncomment one of the sections below, or create your own.
// Then, rename this file to ako-config.jsonc
//
// Note:
// - Make sure you have only one section uncommented
// - You can create or customize your own section
// - Recommendation: Start with a relatively low max_pages number, like 10, and then
//   increase it when you have achieved the desired result on the small subset.

// -- Alchemy (blockchain)
// {
//         "out_dir": "_ako-out",
//        "base_url": "https://www.alchemy.com/",
//      "first_page": "https://www.alchemy.com/docs/reference/token-api-quickstart",
//     "filter_path": "/docs",
//       "max_pages": 10,
//   "exclude_globs": ["**/{debug,llms}*"],
//   "augment_model": "gpt-5-mini-low", // Models can be any providers "gemini-2.5-flash"
//      "llms_model": "gpt-5-mini",
//     "concurrency": 12
// }

// -- OpenAI Cookbook
// {
//         "out_dir": "_ako-out",
//        "base_url": "https://cookbook.openai.com/",
//      "first_page": "https://cookbook.openai.com/examples/gpt4-1_prompting_guide",
//     "filter_path": "/",
//       "max_pages":  10,
//   "augment_model": "gpt-5-mini-low",
//      "llms_model": "gpt-5-mini",
//     "concurrency": 12
// }

// -- Tauri Web Site 
// {
//         "out_dir": "_ako-out",
//        "base_url": "https://tauri.app/",
//      "first_page": "https://tauri.app/reference/acl/capability/",
//     "filter_path": "/reference/",
//       "max_pages":  10,
//   "augment_model": "gpt-5-mini-low",
//      "llms_model": "gpt-5-mini",
//     "concurrency": 12
// }