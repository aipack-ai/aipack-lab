# Options

```toml
# Here can set default agent model, temperature, and input_concurrency
# temperature = 0.0 # not supported in many gpt models
```

# Before All

```lua
local p_utils = require("prompt_utils")

-- If return a string, means not valid, and it's the message
local valid = p_utils.validate_aip_version()
if type(valid) == "string" then
  return aip.flow.skip(valid)
end

-- Get the first input (optional name of the config file) or nil
local input = inputs and inputs[1] or nil

-- input is nil or the config_path
local init_res = p_utils.init_config(input)

if init_res.type == "message" then
  print(init_res.data)
  return
end

-- Assuming type = "config"
local config = init_res.data

local settings = p_utils.build_settings(config)

local files = aip.file.list(settings.dir_2_raw_md  .. "/**/*.md")
for  i, file in ipairs(files) do
    file._display = file.path
end

-- files = { files[1] }

return aip.flow.before_all_response({
    inputs     = files,
    options    = { 
        input_concurrency = config.concurrency, -- if nil, will be the default from aipack
        model = config.augment_model, -- if nil, will be the default from aipack
    },
    before_all = {
        settings     = settings, 
        total_files  = #files
    }
})

```

# Data

```lua

local raw_md_file = input

local dest_dir = before_all.settings.dir_3_final_md

local rel_path      = aip.path.diff(raw_md_file.path, before_all.settings.dir_2_raw_md)
local dest_path     = dest_dir .. "/" .. rel_path

-- if the dest path already exist, we skip
if aip.path.exists(dest_path) then
    return aip.flow.skip("Final file '" .. dest_path .. "' already exist. So, skipping")
end

raw_md_file = aip.file.load(raw_md_file.path)

local prompt_path = before_all.settings.config.augment_prompt
local custom_prompt = nil
if prompt_path and aip.path.exists(prompt_path) then
  custom_prompt = aip.file.load(prompt_path).content
end

aip.run.pin("progress", 0, {label = "Progress:", content = "➜ " .. raw_md_file.path})

print("custom_prompt", custom_prompt)

return {
    raw_md_file   = raw_md_file,
    dest_path     = dest_path,
    custom_prompt = custom_prompt
}
```

> Remove `DISABLED` below to send instruction to AI

# Instruction


- Make it well-structured, with markdown sections.
- Remove the site navigation section; only page content should be kept.
- Use the - character for bullet points.
- Sometimes the markdown link text has an extra blank line; make sure they are all on one line. Inside the [ ... ] there should not be any newline.
- Identify possible code blocks:
  - Remove line numbers.
  - Wrap them in markdown code blocks with the appropriate language.
  - Only use the code block language 'json' for valid JSON content; otherwise 'js' for JavaScript-like content, or 'text'.
  - If it looks like shell command use the `sh` language
  - Indent the code properly.
- For the main page title, use the # level.
- Do not separate sections with `---`


Here is the raw content

````md
{{data.raw_md_file.content}}
````

Return the full file content as is without 
the surrounding in a markdown code block.

# Instruction

{{#if data.custom_prompt}}

Here are some important additional instructions on how to process this raw markdown file

{{data.custom_prompt}}

{{/if}}


# Output 

```lua

local content = ai_response.content
content = aip.md.outer_block_content_or_raw(content)

aip.file.save(data.dest_path, content)

-- aip.run.pin("progress", 0, {label = "Progress:", content = "✔ " .. data.dest_path})

return "➜ " .. data.dest_path
```

# After All 

```lua
local input_len = #inputs
local processed_count = 0
for i, o in ipairs(outputs) do
  -- Doing type check for AIPACK 0.7.17 since it is LigthUserData if skipped
  -- Future version will be "false"
  if type(o) == "string" then
    processed_count = processed_count + 1
  end
end

local msg = "✅ DONE - " .. processed_count .. " AI Augmented"
local skipped_count = input_len - processed_count
if skipped_count > 0 then
    msg = msg .. " - " .. skipped_count .. " already processed."
end

local raw_md_stats   = aip.file.stats(before_all.settings.dir_2_raw_md   .. "/**/*.md")
local final_md_stats = aip.file.stats(before_all.settings.dir_3_final_md .. "/**/*.md")

local raw_size_fmt   = aip.text.format_size(raw_md_stats.total_size)
local final_size_fmt = aip.text.format_size(final_md_stats.total_size)

msg = msg .. "\n"
msg = msg .. "\n  Raw md files: " .. raw_size_fmt
msg = msg .. "\nFinal md files: " .. final_size_fmt

aip.run.pin("progress", 0, {label = "Progress:", content = msg})

-- the .after_all of the agent
return {
    -- to know the number of skipped v.s. processed (since .outputs will be also available)
    total_files     = before_all.total_files,
    processed_count = processed_count,
    skipped_count   = skipped_count,
    raw_size_fmt    = raw_size_fmt,
    final_size_fmt  = final_size_fmt,
}

```