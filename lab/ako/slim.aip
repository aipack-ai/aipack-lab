# Before All

```lua
local p_utils = require("prompt_utils")

-- input is nil or the config_path
local init_res = p_utils.init_config(input)

if init_res.type == "message" then
  print(init_res.data)
  return
end

-- Assuming type = "config"
local config = init_res.data

local SETTINGS = p_utils.build_settings(config)

local CONFIG = SETTINGS.config

local BASE_URL       = CONFIG.base_url
local FIRST_PAGE     = CONFIG.first_page
local FILTER_PATH    = CONFIG.filter_path
local MAX_PAGES      = CONFIG.max_pages

local HAS_EXCLUDE_GLOBS  = config.exclude_globs and next(config.exclude_globs) ~= nil 
local EXCLUDE_GLOBS      = config.exclude_globs

local global_page_counter      = 0
local global_total_orig_size   = 0
local global_total_slim_size   = 0
local global_total_md_raw_size = 0

function process_url(url_str)
  local url_obj   = aip.web.parse_url(url_str)
  aip.run.pin("process", 1, {label = "Processing:", content = url_str})

  local url       = url_obj.url
  local host      = url_obj.host
  local path_obj  = aip.path.parse(url_obj.path)
  local stem      = path_obj.stem
  if stem == "" then
    stem = "index"
  end
  local base_path = path_obj.dir .. "/" .. stem

  local html_res     = aip.web.get(url)
  local html_content = html_res.content

  local original_html_path = SETTINGS.dir_0_original .. "/" .. base_path .. ".html"
  local original_html_file = aip.file.save(original_html_path, html_content)
  global_total_orig_size = global_total_orig_size + original_html_file.size

  local links = aip.html.select(html_content, "a[href]")

  local slim_html_path =  SETTINGS.dir_1_slim_html .. "/" .. base_path .. ".html"
  local html_slim_file = aip.file.save_html_to_slim(original_html_path, slim_html_path)
  global_total_slim_size = global_total_slim_size + html_slim_file.size

  local raw_md_path = SETTINGS.dir_2_raw_md .. "/" .. base_path .. ".md"
  local raw_md_file = aip.file.save_html_to_md(slim_html_path, raw_md_path)
  global_total_md_raw_size = global_total_md_raw_size + raw_md_file.size

  global_page_counter = global_page_counter + 1

  local pages_msg = nil
  if global_page_counter >= MAX_PAGES then
    pages_msg = "✔ "
  else 
    pages_msg = "▶ "
  end
  pages_msg = pages_msg .. global_page_counter .. "/" .. MAX_PAGES

  aip.run.pin("num_pages", 0, {label = "     Pages:", content = pages_msg})

  local progress_msg = ""
  progress_msg =  progress_msg ..   "Original HTMLs: " .. aip.text.format_size(global_total_orig_size, "MB")
  progress_msg  = progress_msg .. "\n  Slimed HTMLs: " .. aip.text.format_size(global_total_slim_size, "MB")
  progress_msg  = progress_msg .. "\n Raw Markdowns: " .. aip.text.format_size(global_total_md_raw_size, "MB")
  aip.run.pin("progress", 0, {label = "     Sizes:", content = progress_msg})

  return {
    original_html_file = original_html_file,
    html_slim_file     = html_slim_file,
    raw_md_file        = raw_md_file,
    links              = links,
  }

end

function process_links(links, page_urls_map) 
  local links_queue = {}
  for i, link in ipairs(links) do
      local href      = aip.web.resolve_href(link.attrs.href, BASE_URL)
      local url_obj   = aip.web.parse_url(href)
      local page_url  = url_obj.page_url
      local url_path  = url_obj.path
      local url       = url_obj.url

      if global_page_counter >= MAX_PAGES then
        return links_queue
      end

      -- if href starts with FILTER_PATH
      if url:sub(1, #BASE_URL) == BASE_URL and url_path:sub(1, #FILTER_PATH) == FILTER_PATH then
        local pass = true
        if HAS_EXCLUDE_GLOBS then
          if aip.path.matches_glob(url_path, EXCLUDE_GLOBS) then 
            print("Exclude glob path (from exclude_globs) " .. url_path)
            pass = false
          end
        end
        -- make sure we do not process twice
        if pass and not page_urls_map[page_url] then
          local links = process_url(page_url).links
          table.insert(links_queue, links)
          page_urls_map[page_url] = true
        end
      end

      ::continue::
  end
  return links_queue
end

-- Map of all of the page_url already processed
local page_urls_map = {}

-- Process initial page, links in the page
local links       = process_url(FIRST_PAGE).links
page_urls_map[FIRST_PAGE] = true

-- Process the links and get a links_queue
local links_queue = process_links(links, page_urls_map)

-- Final process of each links in the links_queue
-- Note: We do not go recursive, just one level down
for i, links in ipairs(links_queue) do
  process_links(links, page_urls_map)
end

local final_msg = "✅ Slim completed. " .. global_page_counter .. " files processed."
local sizes_msg = aip.text.format_size(global_total_orig_size) .. " ➜ " .. aip.text.format_size(global_total_md_raw_size)
sizes_msg = aip.text.trim(sizes_msg)
final_msg = final_msg .. "\n   " .. sizes_msg
aip.run.pin("process", 1, {label = "      DONE:", content = final_msg})

-- Here we make sure the inputs is nil, since it was not for the tasks but for the before_all
return aip.flow.before_all_response({
  inputs     = {},
  before_all = {
    num_of_files          = global_page_counter,
    orig_html_total_size  = global_total_orig_size,
    raw_md_total_size     = global_total_md_raw_size,
  }
})
```

# After All

```lua

return before_all

```